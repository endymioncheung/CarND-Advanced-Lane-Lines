{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advaned Lane Finding Pipeline Outline\n",
    "\n",
    "1. Compute the camera calibration matrix and distortion coefficients given a set of chessboard images.\n",
    "2. Apply a distortion correction to raw images.\n",
    "3. Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "4. Apply a perspective transform to rectify binary image (\"birds-eye view\").\n",
    "\n",
    "\n",
    "5. Detect lane pixels and fit to find the lane boundary.\n",
    "6. Determine the curvature of the lane and vehicle position with respect to center.\n",
    "\n",
    "\n",
    "7. Warp the detected lane boundaries back onto the original image.\n",
    "8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enable interaction window\n",
    "%matplotlib qt\n",
    "%matplotlib inline\n",
    "\n",
    "# import Python libraries\n",
    "import os.path\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import glob\n",
    "from matplotlib.patches import Polygon\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# load/save the previous workspace\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(img1,img2,title1=None,title2=None,save_plot=False):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img1,cmap='gray')\n",
    "    ax1.set_title(title1, fontsize=30)\n",
    "    ax2.imshow(img2,cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=30)\n",
    "    \n",
    "    if save_plot:\n",
    "        plot_fname = title1 + title2;\n",
    "        f.savefig(plot_fname)\n",
    "\n",
    "def show_perspective(img,warped_img,src,dst):\n",
    "    # Plotting combined threshold images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24,9))\n",
    "    f.tight_layout()\n",
    "\n",
    "    # Draw polygon to highlight the four source points on the image\n",
    "    ax1.set_title('Thresholded Image with source points drawn',fontsize=30)\n",
    "    ax1.plot(Polygon(src).get_xy()[:, 0], Polygon(src).get_xy()[:, 1], color='red',linewidth=4)\n",
    "    ax1.imshow(img, cmap='gray') # display in grayscale\n",
    "        \n",
    "    ax2.set_title('Warped result with dest. points drawn',fontsize=30)\n",
    "    # Draw polygon to highlight the four destination points on the image\n",
    "    #ax2.plot(Polygon(dst).get_xy()[:, 0], Polygon(dst).get_xy()[:, 1], color='red',linewidth=4)\n",
    "    ax2.imshow(warped_img, cmap='gray')\n",
    "    \n",
    "    # Draw two vertical lines on the image\n",
    "    ax2.axvline(x=270,color='red',linewidth=4)\n",
    "    ax2.axvline(x=1040,color='red',linewidth=4)\n",
    "    \n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Camera Calibration\n",
    "\n",
    "Compute the camera calibration matrix and and distortion coefficients given a set of chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_camera_calibration(ret,mtx,dist,rvecs,tvecs):\n",
    "  \n",
    "    # Save the camera calibration result for later use (we won't worry about rvecs / tvecs)\n",
    "    dist_pickle = {}\n",
    "    dist_pickle[\"ret\"] = ret\n",
    "    dist_pickle[\"mtx\"] = mtx\n",
    "    dist_pickle[\"dist\"] = dist\n",
    "    dist_pickle[\"rvecs\"] = rvecs\n",
    "    dist_pickle[\"tvec\"] = tvecs\n",
    "    \n",
    "    # Exclude the object and image points to save to the pickle file\n",
    "    # dist_pickle[\"objpoints\"] = objpoints\n",
    "    # dist_pickle[\"imgpoints\"] = imgpoints\n",
    "            \n",
    "    # Save the camera calibration pickle file to the \"camera_cal\" folder\n",
    "    pickle.dump(dist_pickle, open(\"camera_cal/camera_cal.p\", \"wb\" ))\n",
    "\n",
    "def load_camera_calibration(camera_calibration='camera_cal/camera_cal.p'):\n",
    "    if (os.path.isfile(camera_calibration)):\n",
    "        dist_pickle = pickle.load( open(camera_calibration, \"rb\" ) )\n",
    "        ret = dist_pickle[\"ret\"]\n",
    "        mtx  = dist_pickle[\"mtx\"]\n",
    "        dist = dist_pickle[\"dist\"]\n",
    "        rvecs = dist_pickle[\"rvecs\"]\n",
    "        tvecs = dist_pickle[\"tvec\"]\n",
    "    else:\n",
    "        print('ERROR: Unable to open the camera calibration pickle file')\n",
    "        return\n",
    "    return ret, mtx, dist, rvecs, tvecs\n",
    "\n",
    "def map_obj_img_points(img_name, objpoints, imgpoints, visible=True, h_corners=9, v_corners=6):\n",
    "    # Prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((9*6,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9,0:6].T.reshape(-1,2)\n",
    "\n",
    "    img = cv2.imread(img_name)\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (h_corners,v_corners),None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "        \n",
    "        if (visible==True):\n",
    "            # Draw and display the corners\n",
    "            img = cv2.drawChessboardCorners(img, (h_corners,v_corners), corners, ret)\n",
    "            cv2.imshow('img',img)\n",
    "            cv2.waitKey(500)\n",
    "    else:\n",
    "        # Notify the user that some images are not valid for camera calibration\n",
    "        print(\"Unable to detect corners for image : \" + img_name )\n",
    "    return objpoints, imgpoints\n",
    "    \n",
    "def compute_camera_calibration(calibration_images):\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane\n",
    "    \n",
    "    # Make a list of calibration images\n",
    "    images = glob.glob(calibration_images)\n",
    "    \n",
    "    # Step through the list and search for chessboard corners\n",
    "    for fname in images:\n",
    "        img = cv2.imread(fname)\n",
    "        objpoints, imgpoints = map_obj_img_points(fname,objpoints,imgpoints,visible=False)\n",
    "\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    \n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "    return ret, mtx, dist, rvecs, tvecs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsuitable images for camera calibrations\n",
    " \n",
    "Noted that the `calibration1.jpg`, `calibration4.jpg`, `calibration5.jpg` pictures are not suitable for camera calibrations as the not all 9x6 corners could be detected.\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <td> <img src=\"camera_cal/calibration1.jpg\"/> </td>\n",
    "        <td> <img src=\"camera_cal/calibration4.jpg\"/> </td>\n",
    "        <td> <img src=\"camera_cal/calibration5.jpg\"/> </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td> calibration1.jpg <align=\"middle\"/></td>\n",
    "        <td> calibration4.jpg <align=\"middle\"/></td>\n",
    "        <td> calibration5.jpg <align=\"middle\"/></td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Distortion Correction\n",
    "\n",
    "Apply a distortion correction to raw (disorted) images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def undistort_camera_img(img,mtx,dist,show_distortion=False, save_undistort_image=False):   \n",
    "    undist_img = cv2.undistort(img, mtx, dist, None, mtx)       \n",
    "    # save undisort image\n",
    "    if save_undistort_image:\n",
    "        dist_name = os.path.basename(fname)\n",
    "        undist_fname = 'output_images/'+ 'undist_' + os.path.splitext(dist_name)[0] + '.jpg'\n",
    "        cv2.imwrite(undist_fname,undist_img)\n",
    "    # show distortion comparison\n",
    "    if show_distortion:\n",
    "        plot_images(img,undist_img,title1='Camera Image',title2='Undisorted Camera Image')\n",
    "    return undist_img\n",
    "\n",
    "ret, mtx, dist, rvecs, tvecs = load_camera_calibration()\n",
    "images = glob.glob('camera_cal/*.jpg')\n",
    "for fname in images:\n",
    "#     print(fname)\n",
    "    # Read in an image\n",
    "    img = mpimg.imread(fname)\n",
    "    undistort_camera_img(img,mtx,dist,show_distortion=False, save_undistort_image=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Threholding binary images\n",
    "Use color transforms, gradients, etc., to create a thresholded binary image.\n",
    "\n",
    "`The S channel is still doing a fairly robust job of picking up the lines under very different color and contrast conditions`, while the other selections look messy. You could tweak the thresholds and get closer in the other channels, but the S channel is preferable because it is more robust to changing conditions.\n",
    "\n",
    "It's worth noting, however, that `the R channel still does rather well on the white lines, perhaps even better than the S channel`. As with gradients, it's worth considering how you might combine various color thresholds to make the most robust identification of the lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abs_sobel_thresh(img, orient, sobel_kernel, thresh):\n",
    "    # Calculate directional gradient\n",
    "    # Apply threshold\n",
    "\n",
    "    # 1) Convert to grayscale\n",
    "    # 2) Take the derivative in x or y given orient = 'x' or 'y'\n",
    "    # 3) Take the absolute value of the derivative or gradient\n",
    "    # 4) Scale to 8-bit (0 - 255) then convert to type = np.uint8\n",
    "    # 5) Create a mask of 1's where the scaled gradient magnitude \n",
    "            # is > thresh_min and < thresh_max\n",
    "    # 6) Return this mask as your binary_output image\n",
    "    \n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n",
    "    if (orient == 'x'):\n",
    "        # Take the derivative in x\n",
    "        sobel = cv2.Sobel(gray,cv2.CV_64F,1,0,ksize=sobel_kernel)\n",
    "    elif (orient == 'y'):\n",
    "        # Take the derivative in y\n",
    "        sobel = cv2.Sobel(gray,cv2.CV_64F,0,1,ksize=sobel_kernel)\n",
    "    \n",
    "    abs_sobel = np.absolute(sobel)\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    \n",
    "    grad_binary = np.zeros_like(scaled_sobel)\n",
    "    grad_binary[(scaled_sobel >= thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return grad_binary\n",
    "\n",
    "def saturation_thresh(img,s_thresh):\n",
    "    # Convert to HLS color space and separate the S channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    # Threshold saturation channel\n",
    "    s_binary = np.zeros_like(s_channel)\n",
    "    s_binary[(s_channel >= s_thresh[0]) & (s_channel <= s_thresh[1])] = 1\n",
    "\n",
    "    return s_binary\n",
    "\n",
    "def combine_binary_thresh(binary_1,binary_2):\n",
    "    # Combine binary thresholds (saturation and directional gradient)\n",
    "    combined_binary = np.zeros_like(binary_1)\n",
    "    combined_binary[(binary_1 == 1) | (binary_2 == 1)] = 1\n",
    "    \n",
    "    return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Perspective Transform\n",
    "\n",
    "Apply a perspective transform to rectify binary image (\"birds-eye view\"). Using the two straight lines images to verify that the perspective transform is correct. That is the lane lines in the images aligned with the overlayed vertical lines drawn as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp(img,M):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    # Create warped image using linear interpolation\n",
    "    warped_img = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    \n",
    "    return warped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Detect Lane Pixels\n",
    "Detect lane pixels and fit to find the lane boundary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_histogram(img,show_histogram = False):\n",
    "    \n",
    "    # Grab only the bottom half of the image\n",
    "    # Lane lines are likely to be mostly vertical nearest to the car\n",
    "    bottom_half = img[img.shape[0]//2:,:] # floor division\n",
    "    \n",
    "    # Sum across image pixels vertically - make sure to set `axis`\n",
    "    # i.e. the highest areas of vertical lines should be larger values\n",
    "    # along all the columns in the lower half of the image\n",
    "    # The image data. The returned array has shape (M, N) for grayscale images.\n",
    "    histogram = np.sum(bottom_half, axis=0)\n",
    "    \n",
    "    # Plot the binary image and its histogram \n",
    "    if show_histogram:\n",
    "        histogram = get_histogram(img)       \n",
    "        fig = plt.figure()\n",
    "        fig.set_size_inches(8,12)\n",
    "\n",
    "        ax1 = fig.add_subplot(211)\n",
    "        ax1.title.set_text('Curve Lanes #6 Binary')\n",
    "        ax1.imshow(img,cmap='gray')\n",
    "\n",
    "        ax2 = fig.add_subplot(212)\n",
    "        ax2.title.set_text('Histogram')\n",
    "        ax2.plot(histogram)\n",
    "    return histogram\n",
    "\n",
    "def fit_polynomial_pixel_space(img_shape,leftx,lefty,rightx,righty):\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty = np.linspace(0, img_shape[0] - 1, img_shape[0])\n",
    "    \n",
    "    try:\n",
    "        left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "        right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "        \n",
    "        # Calculate the actual bird eye view meters per pixels\n",
    "        left_c = left_fit[0] * img_shape[0] ** 2 + left_fit[1] * img_shape[0] + left_fit[2]\n",
    "        right_c = right_fit[0] * img_shape[0] ** 2 + right_fit[1] * img_shape[0] + right_fit[2]\n",
    "        lane_width_pix = right_c - left_c\n",
    "        xm_per_pix = 3.7 / lane_width_pix\n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "    \n",
    "    return (left_fit, right_fit), ploty, left_fitx, right_fitx, xm_per_pix\n",
    "\n",
    "def detect_lane_lines(img, lines_fit, bad_frames, output_img=False):\n",
    "    # Initalize the lane line search for the first video frame / image\n",
    "    if lines_fit is None:\n",
    "        return full_search_lane_lines(img,bad_frames)\n",
    "    else: \n",
    "        # Otherwise search the lane lines around the polynomial fit \n",
    "        # from the prior video frame\n",
    "        return search_around_poly_lane_lines(img,lines_fit,bad_frames)\n",
    "    \n",
    "def full_search_lane_lines(img, bad_frames, output_img=False):\n",
    "    show_search_window = True\n",
    "        \n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = get_histogram(img)\n",
    "\n",
    "    if output_img:\n",
    "        # Create an output image to draw on and  visualize the result\n",
    "        out_img = np.dstack((img, img, img))*255\n",
    "    \n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]//2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows = 9\n",
    "    \n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]//nwindows)\n",
    "    \n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero  = img.nonzero()\n",
    "    nonzerox = np.array(nonzero[1])   \n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "   \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 100\n",
    "\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 50\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = img.shape[0] - (window + 1)*window_height\n",
    "        win_y_high = img.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        \n",
    "        if output_img:\n",
    "            #Draw the windows on the visualization image\n",
    "            cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high), (0,255,0), 3) \n",
    "            cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high), (0,255,0), 3) \n",
    "        \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                          (nonzerox >= win_xleft_low) &  (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & \n",
    "                           (nonzerox >= win_xright_low) &  (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        \n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        \n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    \n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "    \n",
    "    lines_fit, ploty, left_fitx, right_fitx, xm_per_pix = fit_polynomial_pixel_space(img.shape,leftx,lefty,rightx,righty)\n",
    "    \n",
    "    if output_img:\n",
    "        # Draw left and right pixels in colors\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "        \n",
    "        # Draw the line fit for the left and right lane\n",
    "        for index in range(img.shape[0]):\n",
    "            cv2.circle(out_img, (int(left_fitx[index]), int(ploty[index])), 3, (255,255,0))\n",
    "            cv2.circle(out_img, (int(right_fitx[index]), int(ploty[index])), 3, (255,255,0))\n",
    "\n",
    "        if show_search_window:\n",
    "            # Generate a polygon to illustrate the search window area\n",
    "            # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "            left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "            left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                      ploty])))])\n",
    "            left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "            right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "            right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                      ploty])))])\n",
    "            right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "            # Draw the lane onto the warped blank image\n",
    "            window_img = np.zeros_like(out_img)\n",
    "            cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "            cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "            out_img = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "        return lines_fit, ploty, left_fitx, right_fitx, xm_per_pix, bad_frames,out_img.astype(int)\n",
    "    return lines_fit, ploty, left_fitx, right_fitx, xm_per_pix, bad_frames\n",
    "\n",
    "def search_around_poly_lane_lines(img, lines_fit, bad_frames, output_img=False):\n",
    "    left_fit = lines_fit[0]\n",
    "    right_fit = lines_fit[1]\n",
    "    \n",
    "    # HYPERPARAMETER\n",
    "    # Choose the width of the margin around the previous polynomial to search\n",
    "    margin = 100\n",
    "\n",
    "    # Grab activated pixels\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    ### Set the area of search based on activated x-values ###\n",
    "    ### within the +/- margin of our polynomial function ###\n",
    "    left_lane_inds  = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] - margin))\n",
    "                    &  (nonzerox < (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + left_fit[2] + margin)))\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) \n",
    "                    &  (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))\n",
    "    \n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx  = nonzerox[left_lane_inds]\n",
    "    lefty  = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # If the lines are lost for several frames in a row, retain the previous positions \n",
    "    # from the frame prior and step to the next frame to search again start searching from scratch\n",
    "    # using a histogram and sliding window, \n",
    "    if (leftx.size == 0 or rightx.size == 0):\n",
    "        # Increase bad frame counter when no left and right lane lane pixels are found\n",
    "        bad_frames+=1\n",
    "        \n",
    "        if bad_frames < 5:    \n",
    "            # Generate x and y values for plotting\n",
    "            ploty = np.linspace(0, img_shape[0] - 1, img_shape[0])\n",
    "            left_fitx  = lines_fit[0]\n",
    "            right_fitx = lines_fit[1]\n",
    "\n",
    "            # Calculate the actual bird eye view meters per pixels\n",
    "            left_c = left_fit[0] * img_shape[0] ** 2 + left_fit[1] * img_shape[0] + left_fit[2]\n",
    "            right_c = right_fit[0] * img_shape[0] ** 2 + right_fit[1] * img_shape[0] + right_fit[2]\n",
    "            lane_width_pix = right_c - left_c\n",
    "            xm_per_pix = 3.7 / lane_width_pix\n",
    "            \n",
    "            return lines_fit, ploty, left_fitx, right_fitx, xm_per_pix, bad_frames\n",
    "        else:\n",
    "            # Restart counting the bad frames and start a new search of the lane pixels\n",
    "            bad_frames = 0 \n",
    "            return full_search_lane_lines(img,bad_frames)\n",
    "    \n",
    "    # Fit new polynomials\n",
    "    lines_fit, ploty, left_fitx, right_fitx, xm_per_pix = fit_polynomial_pixel_space(img.shape, leftx, lefty, rightx, righty)\n",
    "    \n",
    "    if output_img:\n",
    "        ## Visualization ##\n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((img, img, img))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "    \n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1 = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2 = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, \n",
    "                                  ploty])))])\n",
    "        left_line_pts = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, \n",
    "                                  ploty])))])\n",
    "        right_line_pts = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "\n",
    "        # Plot the polynomial lines onto the image\n",
    "        plt.plot(left_fitx, ploty, color='yellow')\n",
    "        plt.plot(right_fitx, ploty, color='yellow')\n",
    "        ## End visualization steps ##\n",
    "        return lines_fit, ploty, left_fitx, right_fitx, xm_per_pix, bad_frames, out_img.astype(int)\n",
    "    return lines_fit, ploty, left_fitx, right_fitx, xm_per_pix, bad_frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Determine the curvature of the lane and vehicle position with respect to center.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_polynomial_world_space(ploty, leftx, rightx, ym_per_pix, xm_per_pix):\n",
    "    \n",
    "    leftx = leftx[::-1]    # Reverse to match top-to-bottom in y\n",
    "    rightx = rightx[::-1]  # Reverse to match top-to-bottom in y\n",
    "    \n",
    "    try:        \n",
    "        # Fit polynomials to x,y in world space\n",
    "        left_fit_cr  = np.polyfit(ploty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "        right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "        \n",
    "    except TypeError:\n",
    "        # Avoids an error if `left` and `right_fit` are still none or incorrect\n",
    "        print('The function failed to fit a line!')\n",
    "    \n",
    "    # Second-order polynomial to predict y position\n",
    "    # f(y) = Ay^2 + By + Cf(y)\n",
    "    # Fitting for f(y) rather than f(x) because the lane lines in the warped image \n",
    "    # are near vertical and may have the same x value for more than one y value.\n",
    "    left_A_coeff = left_fit_cr[0]\n",
    "    left_B_coeff = left_fit_cr[1]\n",
    "    left_C_coeff = left_fit_cr[2] # not used for prediction\n",
    "    \n",
    "    right_A_coeff = right_fit_cr[0]\n",
    "    right_B_coeff = right_fit_cr[1]\n",
    "    right_C_coeff = right_fit_cr[2] # not used for prediction\n",
    "    \n",
    "    return left_A_coeff, left_B_coeff, right_A_coeff, right_B_coeff\n",
    "\n",
    "def compute_curvature(img_shape, leftx, rightx, ym_per_pix, xm_per_pix):\n",
    "    ploty = np.linspace(0, img_shape[0]-1, img_shape[0]) # to cover same y-range as image\n",
    "    \n",
    "    # Polynomial line fit in meters (not pixel space any more)\n",
    "    left_A_coeff, left_B_coeff, right_A_coeff, right_B_coeff = fit_polynomial_world_space(ploty, leftx, rightx, ym_per_pix, xm_per_pix)\n",
    "    \n",
    "    # Define y-value where we want radius of curvature\n",
    "    # The y values of image creases from top to bottom, so to measure the radius of curvture closest to the vehicle,\n",
    "    # choose the maximum y-value, corresponding to the bottom of the image\n",
    "    y_eval = np.max(ploty)*ym_per_pix\n",
    "    \n",
    "    # Calculation of R_curve (radius of curvature)\n",
    "    left_curverad = ((1 + (2*left_A_coeff*y_eval + left_B_coeff)**2)**1.5) / np.absolute(2*left_A_coeff)\n",
    "    right_curverad = ((1 + (2*right_A_coeff*y_eval + right_B_coeff)**2)**1.5) / np.absolute(2*right_A_coeff)\n",
    "    \n",
    "    # Estimated lane curvature\n",
    "    radius_of_curvature = (left_curverad + right_curverad)/2\n",
    "    \n",
    "    # The radius of curvature in meters for both lane lines\n",
    "    return radius_of_curvature, left_curverad, right_curverad\n",
    "\n",
    "def compute_veh_offset(img_shape, leftx, rightx, xm_per_pix):\n",
    "    midpointx = img_shape[1]//2\n",
    "        \n",
    "    # Vehicle position with respect to the lane\n",
    "    # Lane center is the midpoint at the bottom of the image between the two lines detected.\n",
    "    veh_posx = (leftx[-1] + rightx[-1])/2\n",
    "    \n",
    "    # Horizontal offset \n",
    "    veh_offsetx = (midpointx - veh_posx) * xm_per_pix\n",
    "\n",
    "    return veh_offsetx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  7. Warp the Detected Lane Boundary\n",
    "Warp the detected lane boundaries back onto the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_lane(img,combined_warped,Minv,ploty,left_fitx,right_fitx):\n",
    "           \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero = np.zeros_like(combined_warped).astype(np.uint8)\n",
    "    color_warp = np.dstack((warp_zero, warp_zero, warp_zero))\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "\n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    new_warp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    out_img = cv2.addWeighted(img, 1, new_warp, 0.3, 0)\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Output visual display of the lane boundaries and numerical estimation of lane curvature and vehicle position."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img,free_text):\n",
    "\n",
    "    # Display lane curvature\n",
    "    out_img = img.copy()\n",
    "    cv2.putText(out_img, free_text, \n",
    "                (60, 100), cv2.FONT_HERSHEY_SIMPLEX, 3, (255,255,255), 5)\n",
    "    \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_estimation(img, radius_of_curvature, veh_offsetx):\n",
    "\n",
    "    # Display lane curvature\n",
    "    out_img = img.copy()\n",
    "    cv2.putText(out_img, 'Radius of Curvature: {:.0f} (m)'.format(radius_of_curvature), \n",
    "                (60, 60), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 5)\n",
    "    \n",
    "    # Display vehicle offset\n",
    "    if veh_offsetx < 0.0: \n",
    "        cv2.putText(out_img, 'Vehicle is {:.2f}m left of center'.format(np.absolute(veh_offsetx)), \n",
    "                    (60, 110), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 5)\n",
    "    else:\n",
    "        cv2.putText(out_img, 'Vehicle is {:.2f}m right of center'.format(veh_offsetx), \n",
    "                    (60, 110), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (255,255,255), 5)\n",
    "    \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_images_vertical(img1,img2,title1=None,title2=None):\n",
    "    f, (ax1, ax2) = plt.subplots(2, 1)\n",
    "    ax1.imshow(img1,cmap='gray')\n",
    "    ax1.set_title(title1, fontsize=30)\n",
    "    ax2.imshow(img2,cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=30)\n",
    "    \n",
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line:\n",
    "    # Initalize the class\n",
    "    def __init__(self, images,always_on_calibrate=True):\n",
    "        # Define conversions in x and y from pixels space to meters\n",
    "        self.ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "        \n",
    "        # The horizontal meters per pixels will not always be 3.7meters/700px\n",
    "        # because the lane width in pixels on your birds-eye view image can differ from 700px\n",
    "        # self.xm_per_pix will be calculated on the fly\n",
    "        #self.xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "        if always_on_calibrate:\n",
    "            # Calibrate camera\n",
    "            self.ret, self.mtx, self.dist, self.rvecs, self.tvecs = compute_camera_calibration(images)\n",
    "            \n",
    "            # Optional save the camera calibration as pickle file\n",
    "            save_camera_calibration(self.ret, self.mtx, self.dist, self.rvecs, self.tvecs)\n",
    "        else:\n",
    "            # Load previous camera calibration\n",
    "            self.ret, self.mtx, self.dist, self.rvecs, self.tvecs = \\\n",
    "            load_camera_calibration(camera_calibration='camera_cal/camera_cal.p')\n",
    "        \n",
    "        # Binary image thresholds\n",
    "        self.orient = 'x'\n",
    "        self.sobel_kernel = 3\n",
    "        self.sx_thresh = [20, 100]\n",
    "        self.s_thresh = [170, 255]\n",
    "\n",
    "        # Pick 4 points to transform\n",
    "        # Note: src and dst points are in [x,y] format\n",
    "        self.src = np.float32(\n",
    "        [[245,  680],  # Bottom left\n",
    "         [580,  460],  # Top left\n",
    "         [710,  460],  # Top right\n",
    "         [1060, 680]]) # Bottom right\n",
    "\n",
    "        self.dst = np.float32(\n",
    "        [[245,  680],  # Bottom left\n",
    "         [245,    0],  # Top left\n",
    "         [1060,   0],  # Top right\n",
    "         [1060, 680]]) # Bottom right\n",
    "    \n",
    "        # The perspective transform matrices\n",
    "        self.M = cv2.getPerspectiveTransform(self.src, self.dst)\n",
    "        self.Minv = cv2.getPerspectiveTransform(self.dst, self.src)\n",
    "        \n",
    "        self.bad_frames = 0\n",
    "        \n",
    "        self.lines_fit = None\n",
    "        \n",
    "        # was the line detected in the last iteration?\n",
    "        self.detected = False  \n",
    "        \n",
    "        # x values of the last n fits of the line\n",
    "        self.recent_xfitted = []\n",
    "        \n",
    "        #x values for detected line pixels\n",
    "        #self.allx = None  \n",
    "        self.leftx = None\n",
    "        self.rightx = None\n",
    "        \n",
    "        #y values for detected line pixels\n",
    "        #self.ally = None\n",
    "        self.ploty = None\n",
    "        \n",
    "        #average x values of the fitted line over the last n iterations\n",
    "        self.bestx = None   \n",
    "        \n",
    "        #polynomial coefficients averaged over the last n iterations\n",
    "        self.best_fit = None\n",
    "        \n",
    "        #polynomial coefficients for the most recent fit\n",
    "        self.current_fit = [np.array([False])]  \n",
    "        \n",
    "        #radius of curvature of the line in some units\n",
    "        self.radius_of_curvature = None \n",
    "        \n",
    "        #distance in meters of vehicle center from the line\n",
    "        self.line_base_pos = None \n",
    "        \n",
    "        #difference in fit coefficients between last and new fits\n",
    "        self.diffs = np.array([0,0,0], dtype='float') \n",
    "        \n",
    "        # Recent\n",
    "        self.recent_lines_fit = None\n",
    "        self.recent_ploty = None\n",
    "        self.recent_leftx = None\n",
    "        self.recent_rightx = None\n",
    "        self.recent_xm_per_pix = None\n",
    "\n",
    "        \n",
    "    # This is a special function active during the life time of the execution    \n",
    "    def __call__(self, img):\n",
    "        \n",
    "        # Apply the image processing to the source image\n",
    "        out_img = self.pipeline(img)\n",
    "        return out_img\n",
    "    \n",
    "    def pipeline(self,img):\n",
    "        # 1. Calibrate camera (see init method)\n",
    "        \n",
    "        # 2. Undistort the image\n",
    "        undist_img = undistort_camera_img(img,mtx=self.mtx,dist=self.dist)\n",
    "        out_img = undist_img\n",
    "        #plot_images(img,undist_img,title1='Camera Image',title2='Undistorted Image')\n",
    "        \n",
    "        # 3. Threholding binary images\n",
    "        # Create gradient-directional threshold binary image\n",
    "        sx_binary = abs_sobel_thresh(undist_img,self.orient,self.sobel_kernel,self.sx_thresh)\n",
    "        #plot_images(undist_img,sx_binary,title1='Undisorted Camera Image',title2='Gradient-directional binary')\n",
    "        \n",
    "        # Create saturation threshold binary image\n",
    "        s_binary = saturation_thresh(undist_img,self.s_thresh)\n",
    "        #plot_images(undist_img,s_binary,title1='Undisorted Camera Image',title2='Saturation binary')\n",
    "        \n",
    "        # Stacked binary\n",
    "        color_binary = np.dstack((np.zeros_like(sx_binary), sx_binary, s_binary)) * 255\n",
    "        # Combined binary\n",
    "        combined_binary = combine_binary_thresh(sx_binary,s_binary)\n",
    "        #plot_images(color_binary,combined_binary,title1='Stacked binary',title2='Combined binary')\n",
    "        \n",
    "        # 4. Perspective Transform\n",
    "        warped_img = warp(undist_img,self.M)\n",
    "        #plot_images(undist_img,warped_img,title1=None,title2=None)\n",
    "        combined_warped = warp(combined_binary,self.M)\n",
    "        #plot_images(warped_img,combined_warped,title1='Bird-eye view',title2='Bird-eye view binary')\n",
    "        \n",
    "        # 5. Detect lane lines\n",
    "        self.lines_fit, self.ploty, self.leftx, self.rightx, self.xm_per_pix, self.bad_frames = detect_lane_lines(combined_warped,self.lines_fit,self.bad_frames)\n",
    "                \n",
    "        # Disable the output image for the detect_lane_lines to save computation\n",
    "        #self.ploty, self.leftx, self.rightx, out_img = detect_lane_lines(combined_warped, output_img=True)\n",
    "        \n",
    "        # 6a. Calculate lane curvature\n",
    "        self.radius_of_curvature, self.left_curvature, self.right_curvature = \\\n",
    "            compute_curvature(combined_warped.shape, self.leftx, self.rightx,\\\n",
    "                                          self.ym_per_pix, self.xm_per_pix)\n",
    "\n",
    "        # 6b. Calculate the vehicle offset relative to the lane center\n",
    "        self.line_base_pos = compute_veh_offset(img.shape, self.leftx, self.rightx, self.xm_per_pix)\n",
    "        \n",
    "        # 7. Draw lane lines on the image\n",
    "        lane_img = draw_lane(img,combined_warped,self.Minv,self.ploty,self.leftx,self.rightx)\n",
    "        out_img = lane_img\n",
    "              \n",
    "        # 8. Display the lane curvature and vehicle offset (to the lane)\n",
    "        out_img = display_estimation(lane_img, self.radius_of_curvature, self.line_base_pos)\n",
    "        \n",
    "        # Free text overlay the image\n",
    "        #out_img = display(out_img,'')\n",
    "        \n",
    "        return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "enable_manual_image_processing = False\n",
    "\n",
    "if enable_manual_image_processing:\n",
    "    # Specify the location of camera calibration\n",
    "    camera_cal_imgs = 'camera_cal/calibration*.jpg'\n",
    "\n",
    "    # Specify the location of the test images\n",
    "    test_imgs='test_images/*.jpg'\n",
    "\n",
    "    # Create a list of images\n",
    "    images = sorted(glob.glob(test_imgs))\n",
    "    for fname in images:\n",
    "        # Read in an image\n",
    "        img = mpimg.imread(fname)\n",
    "        \n",
    "        # Initalize the image processing pipeline\n",
    "        process_image = Line(camera_cal_imgs,always_on_calibrate=False)\n",
    "        \n",
    "        print(os.path.basename(fname))\n",
    "        \n",
    "        # Run the image processing pipeline\n",
    "        out_img = process_image.pipeline(img)\n",
    "        plt.figure()\n",
    "        plt.imshow(out_img)\n",
    "\n",
    "        write_output_image = False\n",
    "        if write_output_image:\n",
    "            output_image = 'output_images/' + os.path.basename(fname)\n",
    "            out_img = cv2.cvtColor(out_img, cv2.COLOR_RGB2BGR)\n",
    "            cv2.imwrite(output_image,out_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video output_videos/project_video.mp4\n",
      "[MoviePy] Writing video output_videos/project_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1260/1261 [02:02<00:00, 10.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: output_videos/project_video.mp4 \n",
      "\n",
      "CPU times: user 13min, sys: 42.9 s, total: 13min 43s\n",
      "Wall time: 2min 3s\n"
     ]
    }
   ],
   "source": [
    "# Helper function to clip section of hte video\n",
    "def clip_video(input_video,t_start,t_end):\n",
    "    video_fname = os.path.basename(input_video)\n",
    "    video_basename = os.path.splitext(video_fname)[0]\n",
    "    video_ext = os.path.splitext(video_fname)[1]\n",
    "    clipped_video_fname = video_basename + '_t=' + str(t_start) + '_t=' + str(t_end) + video_ext\n",
    "\n",
    "    process_clip = VideoFileClip(input_video).subclip(t_start,t_end)\n",
    "    clipped_video = 'output_videos/' + clipped_video_fname\n",
    "    %time process_clip.write_videofile(clipped_video, audio=False)\n",
    "    \n",
    "enable_video_processing = True\n",
    "\n",
    "if enable_video_processing:\n",
    "    video_name = 'project_video.mp4'\n",
    "    \n",
    "    input_video = 'test_videos/' + video_name\n",
    "    output_video = 'output_videos/' + video_name\n",
    "    preprocess_clip = VideoFileClip(input_video)\n",
    "    #preprocess_clip = VideoFileClip(input_video).subclip(0,5.0) #or subclip with the first 5 seconds\n",
    "\n",
    "    # Process video frames with our 'process_image' function\n",
    "    camera_cal_imgs = 'camera_cal/calibration*.jpg'\n",
    "    process_image = Line(camera_cal_imgs,always_on_calibrate=False)\n",
    "\n",
    "    postprocess_clip = preprocess_clip.fl_image(process_image)\n",
    "\n",
    "    %time postprocess_clip.write_videofile(output_video, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "def check_lines_validity(lines_fit, ploty, leftx, rightx, xm_per_pix):\n",
    "    \n",
    "    valid_lines = True\n",
    "    close_to_straightline = False\n",
    "    curvature_not_symmetric = False\n",
    "    top_bottom_not_uniform = False\n",
    "\n",
    "    # TO-DO:\n",
    "    # Check if lane width is in defined borders\n",
    "    # lane lines have the same concavity\n",
    "    min_lane_width  = 3.7\n",
    "    min_dashed_lane_width = 3\n",
    "    \n",
    "    # Polynomial coefficients, f(y) = Ay^2+By+C\n",
    "    left_A_coeff = left_fit[0]\n",
    "    left_B_coeff = left_fit[1]\n",
    "    \n",
    "    right_A_coeff = right_fit[0]\n",
    "    right_B_coeff = right_fit[1]\n",
    "    \n",
    "    average_A_coeff = (left_A_coeff+right_A_coeff)/2\n",
    "    average_B_coeff = (left_B_coeff+right_B_coeff)/2\n",
    "    \n",
    "    ratio_A_coeff = left_A_coeff/right_A_coeff\n",
    "    ratio_B_coeff = left_B_coeff/right_B_coeff\n",
    "\n",
    "    print('A_left={:f} B_left={:f}'.format(left_A_coeff,left_B_coeff))\n",
    "    print('A_right={:f} B_right={:f}'.format(right_A_coeff,right_B_coeff))\n",
    "    print('A Ratio={:f} B Ratio={:f}'.format(ratio_A_coeff,ratio_B_coeff))\n",
    "    print('A/B Ratio={:f}'.format(average_A_coeff/average_B_coeff))\n",
    "    \n",
    "    # Check the ratio of lines curvature is not too big (be careful here with straight lane)\n",
    "    # Identify close to straight-line when A/B Ratio is greater than 0.001636~0.001745\n",
    "    A_B_Ratio_pct = average_A_coeff/average_B_coeff*100\n",
    "    if A_B_Ratio_pct > 0.13:\n",
    "        close_to_straightline = True\n",
    "        print('Close to straightline - because A_B_Ratio_pct={:f}'.format(A_B_Ratio_pct))\n",
    "    \n",
    "    # Check if the left and right lanes have similar curvature\n",
    "    # Check the second degree parameter of both fits are not too different ratio of parameters is less than some value\n",
    "    diff_pct_A_coeff = max(np.absolute(left_A_coeff-average_A_coeff)/average_A_coeff,np.absolute(right_A_coeff-average_A_coeff)/average_A_coeff)*100\n",
    "    if diff_pct_A_coeff > 30:\n",
    "        curvature_not_symmetric = True\n",
    "        print('Curvature not symmetric - because diff_pct_A_coeff={:f}'.format(diff_pct_A_coeff))\n",
    "#         print('diff_pct_A_coeff={:f}'.format(diff_pct_A_coeff))\n",
    "           \n",
    "    # Check the distance between left and right lines at the base of the image is roughly\n",
    "    # the same as at the top of the image (in birds-eye view)\n",
    "    lane_gap_top = np.absolute(leftx[1] + rightx[1]) # top of the image between the two lines detected.\n",
    "    lane_gap_bottom = np.absolute(leftx[-1] + rightx[-1]) # bottom of the image between the two lines detected.\n",
    "    avg_lane_gap_top_bottom = (lane_gap_top+lane_gap_bottom)/2\n",
    "    diff_pct_top_bottom = max(np.absolute(lane_gap_top-avg_lane_gap_top_bottom)/avg_lane_gap_top_bottom,np.absolute(lane_gap_bottom-avg_lane_gap_top_bottom)/avg_lane_gap_top_bottom)*100\n",
    "    if diff_pct_top_bottom > 25:\n",
    "        top_bottom_not_uniform = True\n",
    "        print('Top and bottom not uniform - because diff_pct_top_bottom={:f}'.format(diff_pct_top_bottom))\n",
    "#         print('diff_pct_top_bottom={:f}'.format(diff_pct_top_bottom))\n",
    "        \n",
    "    # Check lane curvature, distance from the center, polynomial coefficients and so on.. \n",
    "    # don't differ a lot from the same values from the previous frame\n",
    "#     avg_radius_of_curvature = (recent_radius_of_curvature+curr_radius_of_curvature)/2\n",
    "#     diff_pct_radius_of_curvature = np.absolute(curr_radius_of_curvature-avg_radius_of_curvature)/avg_radius_of_curvature*100\n",
    "    \n",
    "#     print('diff_pct_radius_of_curvature={:f}'.format(diff_pct_radius_of_curvature))\n",
    "    \n",
    "    if close_to_straightline or curvature_not_symmetric or top_bottom_not_uniform:\n",
    "        valid_lines = False\n",
    "    \n",
    "    return valid_lines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:carnd-term1]",
   "language": "python",
   "name": "conda-env-carnd-term1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
